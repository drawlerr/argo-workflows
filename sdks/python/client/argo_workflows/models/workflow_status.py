# coding: utf-8

"""
    Argo Workflows API

    Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. For more information, please see https://argo-workflows.readthedocs.io/en/latest/

    The version of the OpenAPI document: VERSION
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from typing import Any, ClassVar, Dict, List, Optional
from pydantic import BaseModel, StrictBool, StrictInt, StrictStr
from pydantic import Field
from argo_workflows.models.art_gc_status import ArtGCStatus
from argo_workflows.models.artifact_repository_ref_status import ArtifactRepositoryRefStatus
from argo_workflows.models.condition import Condition
from argo_workflows.models.node_status import NodeStatus
from argo_workflows.models.outputs import Outputs
from argo_workflows.models.synchronization_status import SynchronizationStatus
from argo_workflows.models.template import Template
from argo_workflows.models.volume import Volume
from argo_workflows.models.workflow_spec import WorkflowSpec
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class WorkflowStatus(BaseModel):
    """
    WorkflowStatus contains overall status information about a workflow
    """ # noqa: E501
    artifact_gc_status: Optional[ArtGCStatus] = Field(default=None, alias="artifactGCStatus")
    artifact_repository_ref: Optional[ArtifactRepositoryRefStatus] = Field(default=None, alias="artifactRepositoryRef")
    compressed_nodes: Optional[StrictStr] = Field(default=None, description="Compressed and base64 decoded Nodes map", alias="compressedNodes")
    conditions: Optional[List[Condition]] = Field(default=None, description="Conditions is a list of conditions the Workflow may have")
    estimated_duration: Optional[StrictInt] = Field(default=None, description="EstimatedDuration in seconds.", alias="estimatedDuration")
    finished_at: Optional[datetime] = Field(default=None, description="Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers.", alias="finishedAt")
    message: Optional[StrictStr] = Field(default=None, description="A human readable message indicating details about why the workflow is in this condition.")
    nodes: Optional[Dict[str, NodeStatus]] = Field(default=None, description="Nodes is a mapping between a node ID and the node's status.")
    offload_node_status_version: Optional[StrictStr] = Field(default=None, description="Whether on not node status has been offloaded to a database. If exists, then Nodes and CompressedNodes will be empty. This will actually be populated with a hash of the offloaded data.", alias="offloadNodeStatusVersion")
    outputs: Optional[Outputs] = None
    persistent_volume_claims: Optional[List[Volume]] = Field(default=None, description="PersistentVolumeClaims tracks all PVCs that were created as part of the  The contents of this list are drained at the end of the workflow.", alias="persistentVolumeClaims")
    phase: Optional[StrictStr] = Field(default=None, description="Phase a simple, high-level summary of where the workflow is in its lifecycle. Will be \"\" (Unknown), \"Pending\", or \"Running\" before the workflow is completed, and \"Succeeded\", \"Failed\" or \"Error\" once the workflow has completed.")
    progress: Optional[StrictStr] = Field(default=None, description="Progress to completion")
    resources_duration: Optional[Dict[str, StrictInt]] = Field(default=None, description="ResourcesDuration is the total for the workflow", alias="resourcesDuration")
    started_at: Optional[datetime] = Field(default=None, description="Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers.", alias="startedAt")
    stored_templates: Optional[Dict[str, Template]] = Field(default=None, description="StoredTemplates is a mapping between a template ref and the node's status.", alias="storedTemplates")
    stored_workflow_template_spec: Optional[WorkflowSpec] = Field(default=None, alias="storedWorkflowTemplateSpec")
    synchronization: Optional[SynchronizationStatus] = None
    task_results_completion_status: Optional[Dict[str, StrictBool]] = Field(default=None, description="TaskResultsCompletionStatus tracks task result completion status (mapped by pod name). Used to prevent premature archiving and garbage collection.", alias="taskResultsCompletionStatus")
    __properties: ClassVar[List[str]] = ["artifactGCStatus", "artifactRepositoryRef", "compressedNodes", "conditions", "estimatedDuration", "finishedAt", "message", "nodes", "offloadNodeStatusVersion", "outputs", "persistentVolumeClaims", "phase", "progress", "resourcesDuration", "startedAt", "storedTemplates", "storedWorkflowTemplateSpec", "synchronization", "taskResultsCompletionStatus"]

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of WorkflowStatus from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of artifact_gc_status
        if self.artifact_gc_status:
            _dict['artifactGCStatus'] = self.artifact_gc_status.to_dict()
        # override the default output from pydantic by calling `to_dict()` of artifact_repository_ref
        if self.artifact_repository_ref:
            _dict['artifactRepositoryRef'] = self.artifact_repository_ref.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in conditions (list)
        _items = []
        if self.conditions:
            for _item in self.conditions:
                if _item:
                    _items.append(_item.to_dict())
            _dict['conditions'] = _items
        # override the default output from pydantic by calling `to_dict()` of each value in nodes (dict)
        _field_dict = {}
        if self.nodes:
            for _key in self.nodes:
                if self.nodes[_key]:
                    _field_dict[_key] = self.nodes[_key].to_dict()
            _dict['nodes'] = _field_dict
        # override the default output from pydantic by calling `to_dict()` of outputs
        if self.outputs:
            _dict['outputs'] = self.outputs.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in persistent_volume_claims (list)
        _items = []
        if self.persistent_volume_claims:
            for _item in self.persistent_volume_claims:
                if _item:
                    _items.append(_item.to_dict())
            _dict['persistentVolumeClaims'] = _items
        # override the default output from pydantic by calling `to_dict()` of each value in stored_templates (dict)
        _field_dict = {}
        if self.stored_templates:
            for _key in self.stored_templates:
                if self.stored_templates[_key]:
                    _field_dict[_key] = self.stored_templates[_key].to_dict()
            _dict['storedTemplates'] = _field_dict
        # override the default output from pydantic by calling `to_dict()` of stored_workflow_template_spec
        if self.stored_workflow_template_spec:
            _dict['storedWorkflowTemplateSpec'] = self.stored_workflow_template_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of synchronization
        if self.synchronization:
            _dict['synchronization'] = self.synchronization.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of WorkflowStatus from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "artifactGCStatus": ArtGCStatus.from_dict(obj.get("artifactGCStatus")) if obj.get("artifactGCStatus") is not None else None,
            "artifactRepositoryRef": ArtifactRepositoryRefStatus.from_dict(obj.get("artifactRepositoryRef")) if obj.get("artifactRepositoryRef") is not None else None,
            "compressedNodes": obj.get("compressedNodes"),
            "conditions": [Condition.from_dict(_item) for _item in obj.get("conditions")] if obj.get("conditions") is not None else None,
            "estimatedDuration": obj.get("estimatedDuration"),
            "finishedAt": obj.get("finishedAt"),
            "message": obj.get("message"),
            "nodes": dict(
                (_k, NodeStatus.from_dict(_v))
                for _k, _v in obj.get("nodes").items()
            )
            if obj.get("nodes") is not None
            else None,
            "offloadNodeStatusVersion": obj.get("offloadNodeStatusVersion"),
            "outputs": Outputs.from_dict(obj.get("outputs")) if obj.get("outputs") is not None else None,
            "persistentVolumeClaims": [Volume.from_dict(_item) for _item in obj.get("persistentVolumeClaims")] if obj.get("persistentVolumeClaims") is not None else None,
            "phase": obj.get("phase"),
            "progress": obj.get("progress"),
            "resourcesDuration": obj.get("resourcesDuration"),
            "startedAt": obj.get("startedAt"),
            "storedTemplates": dict(
                (_k, Template.from_dict(_v))
                for _k, _v in obj.get("storedTemplates").items()
            )
            if obj.get("storedTemplates") is not None
            else None,
            "storedWorkflowTemplateSpec": WorkflowSpec.from_dict(obj.get("storedWorkflowTemplateSpec")) if obj.get("storedWorkflowTemplateSpec") is not None else None,
            "synchronization": SynchronizationStatus.from_dict(obj.get("synchronization")) if obj.get("synchronization") is not None else None,
            "taskResultsCompletionStatus": obj.get("taskResultsCompletionStatus")
        })
        return _obj


